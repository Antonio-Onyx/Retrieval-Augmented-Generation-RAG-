{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBi76DeyadKazaJtOPr9iL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4Lt421mN2KU",
        "outputId": "3677faff-79fc-4d29-f601-c8d5e486c57f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.29.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "  !pip install groq\n",
        "  from groq import Groq\n",
        "except:\n",
        "  pass\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Probando Groq"
      ],
      "metadata": {
        "id": "UCOZCKydW5E8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  #groq_api_key = userdata.get(\"GROQ_API_KEY\")\n",
        "  groq_api_key = \"aqui va el api key\"\n",
        "except Exception as e:\n",
        "  print(f\"Error al cargar la clave de Groq {e}\")"
      ],
      "metadata": {
        "id": "iPojzIV8PKFd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = Groq(\n",
        "    api_key=groq_api_key\n",
        ")"
      ],
      "metadata": {
        "id": "sJoeXnsFPge6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\":\"user\",\n",
        "            \"content\":\"Explica el mecanismo de atencion en los transformers\"\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama3-70b-8192\"\n",
        ")\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24tmATR0Py0D",
        "outputId": "e8d187fa-fb8a-4746-c12b-2f16805dd0f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uno de los conceptos más interesantes y poderosos en la arquitectura de los Transformers: la atención (Attention Mechanism)!\n",
            "\n",
            "La atención es un mecanismo clave en la arquitectura de los Transformers, introducida originalmente por Vaswani et al. en su paper \"Attention is All You Need\" (2017). Este mecanismo permite que el modelo se centre en las partes más relevantes de la entrada mientras procesa la información, lo que mejora significativamente su capacidad para capturar relaciones entre diferentes partes de la entrada.\n",
            "\n",
            "**Cómo funciona la atención en los Transformers**\n",
            "\n",
            "En un Transformer, la atención se aplica en la capa de \" self-attention\" (atención a sí mismo), que es una parte crítica del modelo. La atención se utiliza para calcular la representación de cada posición en la secuencia de entrada, ponderando la importancia de cada una de las otras posiciones.\n",
            "\n",
            "El mecanismo de atención se puede descomponer en tres pasos:\n",
            "\n",
            "1. **Crear matrices de queries (Q), keys (K) y values (V)**: se transforman las representaciones de la entrada en tres matrices: queries (Q), keys (K) y values (V). Estas matrices se utilizan para calcular la atención.\n",
            "2. **Calcular la atención**: se calcula la atención ponderada entre cada par de posiciones en la secuencia de entrada. Esto se hace mediante la siguiente fórmula:\n",
            "\n",
            "$$Attention(Q, K, V) = softmax(\\frac{Q \\cdot K^T}{\\sqrt{d_k}}) \\cdot V$$\n",
            "\n",
            "Donde:\n",
            "\n",
            "* $Q$, $K$ y $V$ son las matrices de queries, keys y values, respectivamente.\n",
            "* $d_k$ es la dimensión de las matrices de keys.\n",
            "* $softmax$ es una función de activación que asegura que las entradas se suman a 1.\n",
            "\n",
            "La atención se calcula como la softmax de la matriz de producto punto entre las matrices de queries y keys, dividida por la raíz cuadrada de la dimensión de las matrices de keys. Luego, se hace el producto punto entre la atención y la matriz de values para obtener la representación final.\n",
            "\n",
            "3. **Combinar la atención con la representación original**: la atención se combina con la representación original de la entrada utilizando una operación de suma o concatenación.\n",
            "\n",
            "**Vías de atención**\n",
            "\n",
            "En un Transformer, hay tres tipos de atención:\n",
            "\n",
            "* **Self-attention**: la atención se aplica a la misma secuencia de entrada.\n",
            "* **Encoder-decoder attention**: la atención se aplica entre la secuencia de entrada y la secuencia de salida.\n",
            "* **Multi-head attention**: se utilizan varias matrices de queries, keys y values, lo que permite que el modelo capture relaciones diferentes entre las posiciones en la secuencia de entrada.\n",
            "\n",
            "La atención es una herramienta poderosa que permite que los Transformers capture relaciones complejas entre las posiciones en la secuencia de entrada, lo que mejora significativamente su capacidad para realizar tareas de procesamiento de lenguaje natural.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vamos a empezar con la estructura del RAG"
      ],
      "metadata": {
        "id": "YRaQn9cWbTRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieval"
      ],
      "metadata": {
        "id": "LLijJGkevSti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  !pip install langchain_community\n",
        "  !pip install pypdf\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "o_0Nmut-eUL-",
        "outputId": "30745319-eb95-468e-e7e4-bca8f607862c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.66)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.26)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### text splitter"
      ],
      "metadata": {
        "id": "Oleh6pdCvZiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "__IUB8TubYqO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=5000,\n",
        "    chunk_overlap=500,\n",
        "    add_start_index=True,\n",
        ")"
      ],
      "metadata": {
        "id": "_SJWwC-qctUK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/gauss_fields.pdf\"\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "documents = loader.load()\n",
        "print(f\"Documento cargado, numero de paginas {len(documents)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2ULQ9qneurZ",
        "outputId": "cae658b7-0147-4239-85a1-d1a87e8adeaa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento cargado, numero de paginas 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcRl_F1vbnAN",
        "outputId": "db128aac-3acb-4cab-e6c9-db5bd7bfc8e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.document_loaders.pdf.PyPDFLoader at 0x7824faa80610>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "HA6vw7Hhfstr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Número de chunks: {len(chunks)}\")\n",
        "print(\"\\n Primer chunk:\")\n",
        "print(chunks[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJtnj_Tof1KJ",
        "outputId": "55212dc3-d798-4a04-cb22-5febe866e022"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de chunks: 19\n",
            "\n",
            " Primer chunk:\n",
            "arXiv:2006.11870v1  [math.NT]  21 Jun 2020\n",
            "GENUS FIELDS OF KUMMER ℓn–CYCLIC EXTENSIONS\n",
            "CARLOS DANIEL REYES–MORALES AND GABRIEL VILLA–SAL V ADOR\n",
            "A B S T R A C T . W e give a construction of the genus ﬁeld for Kummer ℓn-cyclic ex-\n",
            "tensions of rational congruence function ﬁelds, where ℓ is a prime number . First,\n",
            "we compute the genus ﬁeld of a ﬁeld contained in a cyclotomic f unction ﬁeld, and\n",
            "then for the general case. This generalizes the result obtai ned by Peng for a Kum-\n",
            "mer ℓ-cyclic extension. Finally , we study the extension (K1K2)ge/(K1)ge(K2)ge,\n",
            "for K1, K2 abelian extensions of k.\n",
            "1. I NT RODU CT ION\n",
            "The origin of genus ﬁelds dates back to C. F . Gauss [8] in his wo rk about binary\n",
            "quadratic forms. For a ﬁnite ﬁeld extension K of Q, the rational number ﬁeld, the\n",
            "genus ﬁeld Kge is deﬁned as the maximum unramiﬁed ﬁeld extension of K such\n",
            "that it is the composite Kk∗, where k∗ is an abelian ﬁeld extension over Q. This\n",
            "deﬁnition is due to A. Fr ¨ ohlich [7]. W e have K ⊆ Kge ⊆ KH , where KH denotes\n",
            "the Hilbert class ﬁeld over K. Originally the concept of genus ﬁelds was given for\n",
            "quadratic ﬁeld extensions of Q.\n",
            "Using Dirichlet characters, H. W . Leopoldt [12] determined the narrow genus\n",
            "ﬁeld Kgex of a ﬁnite abelian ﬁeld extension K over Q, i.e, Kgex is the maximum\n",
            "abelian ﬁeld extension of Q such that Kgex/K is unramiﬁed at any ﬁnite prime of\n",
            "K. This generalizes the results of H. Hasse [9] who introduced genus theory for\n",
            "quadratic extensions of number ﬁelds.\n",
            "M. Ishida described the narrow genus ﬁeld Kgex of any ﬁnite extension of Q\n",
            "[11]. X. Zhang [20] gave a simple expression of Kge of any ﬁnite abelian extension\n",
            "K of Q using Hilbert ramiﬁcation theory .\n",
            "For function ﬁelds, the notion of Hilbert class ﬁeld as the ma ximum unrami-\n",
            "ﬁed abelian extension of a congruence function ﬁeld K/Fq is not suitable since it\n",
            "contains all the constant ﬁeld extensions Km := KFqm for every natural number\n",
            "m. Therefore the maximum unramiﬁed abelian extension of K is of inﬁnite degree\n",
            "over K.\n",
            "M. Rosen [17] gave a deﬁnition of an analogue of the Hilbert cl ass ﬁeld of K for\n",
            "a ﬁxed ﬁnite nonempty set S of prime divisors of K. Given a ﬁnite nonempty set\n",
            "S of places of a global function ﬁeld K, the Hilbert class ﬁeld (relative to S) KH,S\n",
            "of K is deﬁned as the maximum unramiﬁed abelian extension of K such that the\n",
            "places in S are completely descomposed in KH,S . Using Rosen’s deﬁnition of\n",
            "Hilbert class ﬁeld, it is possible to give a proper concept of genus ﬁelds along the\n",
            "lines of number ﬁelds.\n",
            "Date: June 21, 2020.\n",
            "2010 Mathematics Subject Classiﬁcation. Primary 11R60; Secondary 11R29, 11R58.\n",
            "Key words and phrases. Genus ﬁelds, Kummer extensions, congruence function ﬁelds , global ﬁelds,\n",
            "Dirichlet characters, cyclotomic function ﬁelds, cyclic e xtensions.\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding\n",
        "embedding model from HungginFace"
      ],
      "metadata": {
        "id": "Gy63Ir1lgz_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  !pip install -qU langchain-huggingface\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "mjfe0cG6gzPs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTXTfLdUh07O",
        "outputId": "ec50f518-eead-47ab-aa80-a3ce254c167e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_1 = embeddings.embed_query(chunks[0].page_content)\n",
        "vector_2 = embeddings.embed_query(chunks[1].page_content)\n",
        "\n",
        "assert len(vector_1) == len(vector_2)\n",
        "print(f\"Generated vectors of length {len(vector_1)}\\n\")\n",
        "print(vector_1[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBKdpAS3ipPV",
        "outputId": "8fef5eff-214f-4153-dbf6-56403ec3672f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated vectors of length 384\n",
            "\n",
            "[-0.09074479341506958, 0.06299955397844315, 0.06687162071466446, -0.02946328930556774, -0.03094075806438923, 0.011214579455554485, 0.039026226848363876, 0.03662385419011116, 0.05328264832496643, -0.04078393429517746]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector stores"
      ],
      "metadata": {
        "id": "NLKqQ7MJjP8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  !pip install faiss-cpu\n",
        "except:\n",
        "  pass\n",
        "\n",
        "import faiss\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ku3UjIZjO_B",
        "outputId": "2978c3ae-b6d2-4bb2-d74c-67ce926b1bc8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = len(embeddings.embed_query(\"Hola Mundo\"))\n",
        "index = faiss.IndexFlatL2(embedding_dim)\n",
        "\n",
        "vector_store = FAISS(\n",
        "    embedding_function=embeddings,\n",
        "    index=index,\n",
        "    docstore=InMemoryDocstore(), # los documentos se almacenan en la RAM de la pc\n",
        "    index_to_docstore_id={}\n",
        ")"
      ],
      "metadata": {
        "id": "VSh2Zyi1n4X6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = vector_store.add_documents(documents=chunks)"
      ],
      "metadata": {
        "id": "4tyGmlOYoxvd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHZ-TDtepvcK",
        "outputId": "d7d0a178-30ec-4cb0-cccc-393ab4b352d9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['805e27d4-2888-45e5-bbd0-b620182db836',\n",
              " '5979c5ae-4b4c-4b9a-a944-845b4b1ec80e',\n",
              " '56c241d7-c688-4d52-9637-d107ef0c7a30',\n",
              " '8d62cd24-ec39-4f95-8a03-660177a81e06',\n",
              " 'c8e478cd-bc35-4bcf-a625-0456387d7226',\n",
              " '9f2c6d47-f004-4ac1-8564-b329de1ad33f',\n",
              " '9adabc3f-6203-4854-a40e-afc8c0d87787',\n",
              " 'c5c281de-8009-4bee-a067-17fa8993a5d0',\n",
              " '96df238e-8da1-4540-b5c5-173d03c19920',\n",
              " 'f8901eca-a66f-48ec-881a-714e1a30f097',\n",
              " 'c0b688ef-7204-42c3-a240-d1f583ce2758',\n",
              " 'e747f59e-ea62-4a95-b1b6-dba1141329f4',\n",
              " '801150fe-6936-4f76-abd1-a00462f6d8cd',\n",
              " '392c276a-23e8-4320-83fc-aae622272d96',\n",
              " 'c06b2963-42fd-4e52-90b7-bdc4e1f3a3c1',\n",
              " '03a5c421-c277-4b7c-88d2-9ab57e5d7b4d',\n",
              " '518812f3-2fb4-4c45-9afd-96d31b32c989',\n",
              " '1bdd9beb-887f-481c-a84b-ac36f0f675d9',\n",
              " '07922309-9bae-4838-9367-3d4100d92e28']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = vector_store.similarity_search(\n",
        "    \"genus field\"\n",
        ")\n",
        "\n",
        "print(results[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFGEeZ-OqF0k",
        "outputId": "f3d6eabe-490e-459f-a580-7cae544bbb6e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='GENUS FIELDS OF KUMMER ℓn–CYCLIC EXTENSIONS 19\n",
            "DE PA RTA M E N T O D E CO N T R O L A U T O M ´A T IC O , C E N T R O D E IN V E S T I G A C I ´O N Y D E E S T U D I O S AVA N-\n",
            "Z A D O S D E L I. P . N.\n",
            "E-mail address : mcenigm@gmail.com, creyes@ctrl.cinvestav.mx\n",
            "DE PA RTA M E N T O D E CO N T R O L A U T O M ´A T IC O , C E N T R O D E IN V E S T I G A C I ´O N Y D E E S T U D I O S AVA N-\n",
            "Z A D O S D E L I. P . N.\n",
            "E-mail address : gvillasalvador@gmail.com, gvilla@ctrl.cinvestav.mx' metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2021-11-08T03:55:40-05:00', 'moddate': '2021-11-08T03:55:40-05:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '/content/gauss_fields.pdf', 'total_pages': 19, 'page': 18, 'page_label': '19', 'start_index': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = await vector_store.asimilarity_search(\"What does the proposition 2.1. say?\")\n",
        "print(results[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSVvru9Hq2ub",
        "outputId": "5d24e086-2cf9-42ce-b6af-33dc32650c3c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='14 C. REYES AND G. VILLA\n",
            "Proposition 5.3. Let K1, K2 ⊆ nk(Λ N )m, K = K1K2 and E1, E2 as before. If Kge =\n",
            "(K1)ge(K2)ge, then Ege = ( E1)ge(E2)ge.\n",
            "Proof. Let K = K1K2 ⊆ nk(Λ N )m and E := E1E2 ⊆ k(Λ N ). Consider the ﬁelds\n",
            "(Kge)m and (Ege)m. Now , from [4, Theorem 2.2] we have (Ege)m = ( Kge)m and\n",
            "((Ki)ge)m = (( Ei)ge)m, i = 1 , 2. Therefore\n",
            "(Ege)m = ( Kge)m = (( K1)ge(K2)ge)m = (( K1)ge)m((K2)ge)m\n",
            "= (( E1)ge)m((E2)ge)m = (( E1)ge(E2)ge)m.\n",
            "Finally , by the Galois correspondence, it follows\n",
            "Ege = ( Ege)m ∩ k(Λ N ) = (( E1)ge(E2)ge)m ∩ k(Λ N ) = ( E1)ge(E2)ge.\n",
            "□\n",
            "The converse of Proposition 5.2 does not hold in general, tha t is, if Ege =\n",
            "(E1)ge(E2)ge, then the equality Kge = ( K1)ge(K2)ge may fail.\n",
            "Example 5.4. Let K1 = k( ℓ√P1), K2 = k( ℓ√γP2) and K = K1K2 be such that\n",
            "P1, P2 ∈ R+\n",
            "T are different polynomials with deg P1 = a, 1 ≤ a < ℓ , deg P2 = ℓ − a\n",
            "and γ /∈ (F∗\n",
            "q )ℓ. Then we have Ei = k( ℓ\n",
            "√\n",
            "(Pi)∗), i = 1 , 2 and E = E1E2. If χPi is the\n",
            "Dirichlet character associated with the ﬁeld Ei, i = 1 , 2, by Leopoldt’s Theorem\n",
            "([18, Proposition 14.4.1]), we have Ei = ( Ei)ge, i = 1 , 2 and Ege = E1E2 = E.\n",
            "Therefore Ege = E = E1E2 = ( E1)ge(E2)ge.\n",
            "Now , since P∞ is ramiﬁed in Ki/k, i = 1 , 2, we have that P∞ is of degree 1 in Ki\n",
            "and (Ki)ge = Ki. On the other hand, from Abhyankar ’s Lemma, the remiﬁcation\n",
            "of P∞ in K/k is equal to lcm[e∞(K1/k), e∞(K2/k)] = ℓ. Since k( ℓ√γP1P2) ⊆ K,\n",
            "with deg P1P2 = deg P1 + deg P2 = ℓ, thus, ℓ | deg P1P2 and γ /∈ (F∗\n",
            "q )ℓ, we obtain\n",
            "f∞(K/k) = ℓ. Also we have [K : k] = ℓ2 = f∞(K/k)e∞(K/k). It follows that\n",
            "h∞(K/k) = 1 and deg (S∞(K)) = f∞(K/k) = ℓ. Thus [KFqℓ : K] = ℓ and\n",
            "K ⊊ KFqℓ ⊆ Kge, i.e, Kge ̸= K = K1K2 = ( K1)ge(K2)ge.\n",
            "The main result of this section is the following theorem.\n",
            "Theorem 5.5. Let K1, K2/k be abelian ﬁnite ﬁeld extensions. Then\n",
            "[(K1K2)ge : ( K1)ge(K2)ge] | (q − 1)2.\n",
            "Proof. W e have K1, K2 ⊆ nk(Λ N )m for some m ∈ N, n ∈ N ∪ {0} and N ∈ RT . Let\n",
            "K = K1K2 ⊆ nk(Λ N )m. Let Ei = n(Ki)m ∩ k(Λ N ), i = 1 , 2 y E = nKm ∩ k(Λ N ).\n",
            "Then E = E1E2. Now , since E+\n",
            "gex ∩ Ege = Egex ∩ k(Λ N )+ ∩ Ege = Egex ∩ E+\n",
            "ge = E+\n",
            "ge,\n",
            "we have the following Galois square.\n",
            "E+\n",
            "gex\n",
            "E+\n",
            "gexEge\n",
            "E+\n",
            "ge Ege\n",
            "From [4, Theorem 2.1] we have Ege = E+\n",
            "gexE. Then from the Galois corre-\n",
            "spondence we obtain E+\n",
            "ge = E+\n",
            "gex. Similarly (Ei)+\n",
            "ge = ( Ei)+\n",
            "gex, i = 1 , 2. W e\n",
            "have [E+\n",
            "gex : ( E1)+\n",
            "gex(E2)+\n",
            "gex] | q − 1. In particular [E+\n",
            "ge : ( E1)+\n",
            "ge(E2)+\n",
            "ge] = [ E+\n",
            "gex :' metadata={'producer': 'dvips + GPL Ghostscript GIT PRERELEASE 9.22', 'creator': 'LaTeX with hyperref package', 'creationdate': '2021-11-08T03:55:40-05:00', 'moddate': '2021-11-08T03:55:40-05:00', 'title': '', 'subject': '', 'author': '', 'keywords': '', 'source': '/content/gauss_fields.pdf', 'total_pages': 19, 'page': 13, 'page_label': '14', 'start_index': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieval & Generations\n",
        "\n",
        "integracion del mecanismo de recuperacion con Groq"
      ],
      "metadata": {
        "id": "PX6P_qvgwB0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  !pip install -qU langchain-groq\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "Z93eL6qjwFhd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = groq_api_key"
      ],
      "metadata": {
        "id": "nHqCEkMnzAn0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama3-70b-8192\",\n",
        "    temperature=0.8,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2\n",
        ")"
      ],
      "metadata": {
        "id": "3fR8Xt6gxRCu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### creando el retriever"
      ],
      "metadata": {
        "id": "NjO8G_9-zhVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5}) # recuperar los 5 vectores más similares o en otras palabras los 3 documentos más relevantes"
      ],
      "metadata": {
        "id": "Vxt-uC34zXBW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### plantilla para el prompt"
      ],
      "metadata": {
        "id": "uHN6MMN10PzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "wuRxLLMy0KYJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "Eres un asistente de investigacion inteligente y traductor simultaneo. Tu tarea es responder a las preguntas del usuario basandote estrictamente en el 'Contexto' proporcionado.\n",
        "\n",
        "Instrucciones:\n",
        "1. Lee cuidadosamente la 'pregunta del usuario' y el 'contexto' que se te proporciona. Ambos estaran en ingles.\n",
        "2. Utiliza únicamente la información que encuentres en el 'Contexto' para formular tu respuesta. No uses conocimiento externo.\n",
        "3. Si la respuesta puede encontrarse en el 'Contexto', formula una respuesta clara y concisa en **ESPAÑOL**.\n",
        "4. Si la información necesaria para responder la pregunta no está presente en el 'Contexto', simplemente indica en español: \"Lo siento, no tengo suficiente información en los documentos proporcionados para responder a esa pregunta.\".\n",
        "5. Evita inventar información o hacer suposiciones.\n",
        "6. Manten tus respuestas objetivas y neutrales.\n",
        "\n",
        "Contexto:\n",
        "{context}\n",
        "\n",
        "Pregunta:\n",
        "{question}\n",
        "\n",
        "Respuesta:\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "WWqM-x2N0fNI"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUftP62z1Vrq",
        "outputId": "e3bdae8d-8e25-40c0-ee10-b0193cb58c84"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\nEres un asistente de investigacion inteligente y traductor simultaneo. Tu tarea es responder a las preguntas del usuario basandote estrictamente en el \\'Contexto\\' proporcionado.\\n\\nInstrucciones:\\n1. Lee cuidadosamente la \\'pregunta del usuario\\' y el \\'contexto\\' que se te proporciona. Ambos estaran en ingles.\\n2. Utiliza únicamente la información que encuentres en el \\'Contexto\\' para formular tu respuesta. No uses conocimiento externo.\\n3. Si la respuesta puede encontrarse en el \\'Contexto\\', formula una respuesta clara y concisa en **ESPAÑOL**.\\n4. Si la información necesaria para responder la pregunta no está presente en el \\'Contexto\\', simplemente indica en español: \"Lo siento, no tengo suficiente información en los documentos proporcionados para responder a esa pregunta.\".\\n5. Evita inventar información o hacer suposiciones.\\n6. Manten tus respuestas objetivas y neutrales.\\n\\nContexto:\\n{context}\\n\\nPregunta:\\n{question}\\n\\nRespuesta:\\n'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "aqui vamos a conectar todas las piezas"
      ],
      "metadata": {
        "id": "c9uB1l0U4_Mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "rag_chain = (\n",
        "    {'context': retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "ZRcr9mzC1dOM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# echando a andar el RAG"
      ],
      "metadata": {
        "id": "co6KIei3-NyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "consulta = \"Desde donde viene el origen del Genus Field?\"\n",
        "respuesta = rag_chain.invoke(consulta)\n",
        "print(f\"Pregunta: {consulta}\")\n",
        "print(f\"Respuesta: {respuesta}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81S7i6l75Dh-",
        "outputId": "de2d39a8-7791-4f84-9156-c97fef39ba43"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregunta: Desde donde viene el origen del Genus Field?\n",
            "Respuesta: Según el contexto, el origen del Genus Field se remonta a la obra de C. F. Gauss sobre formas cuadradas binarias.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "consulta_2 = \"De qué trata el documento Genus field of kummer?\"\n",
        "respuesta_2 = rag_chain.invoke(consulta_2)\n",
        "print(f\"Pregunta: {consulta_2}\")\n",
        "print(f\"Respuesta: {respuesta_2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpUma0KG7Da3",
        "outputId": "824546c2-54ed-423a-bb5c-64340c7b55dc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregunta: De qué trata el documento Genus field of kummer?\n",
            "Respuesta: El documento \"Genus Fields of Kummer ℓn–Cyclic Extensions\" trata sobre la construcción del campo de género para extensiones cíclicas de Kummer de campos de congruencia funcionales, donde ℓ es un número primo. El documento proporciona una definición de campo de género para campos de congruencia funcionales y estudia sus propiedades, incluyendo la relación entre el campo de género y el campo de clase de Hilbert. También se presentan resultados sobre la estructura del campo de género para extensiones cíclicas de Kummer y se comparan con resultados previos en la literatura.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "consulta_3 = \"Cual es la documentación que se esta usando en el documento?\"\n",
        "respuesta_3 = rag_chain.invoke(consulta_3)\n",
        "print(f\"Pregunta: {consulta_3}\")\n",
        "print(f\"Respuesta: {respuesta_3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAsDyKCq8dv-",
        "outputId": "136bcb53-d625-4cd1-db42-c442f3127c68"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregunta: Cual es la documentación que se esta usando en el documento?\n",
            "Respuesta: La documentación que se está usando en el documento se refiere a la lista de referencias bibliográficas etiquetadas con números del 1 al 20. Estas referencias incluyen artículos de investigación, libros y otros trabajos académicos en el campo de las matemáticas, específicamente en teoría de números y álgebra.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "consulta_4 = \"en el documento qué es lo que dice la proposition2.1.\"\n",
        "respuesta_4 = rag_chain.invoke(consulta_4)\n",
        "print(f\"Pregunta: {consulta_4}\")\n",
        "print(f\"Respuesta: {respuesta_4}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlBQPsHp9jSE",
        "outputId": "a6c871cf-3a34-4e6c-8cf0-da516110ca64"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregunta: en el documento qué es lo que dice la proposition2.1.\n",
            "Respuesta: Lo siento, no tengo suficiente información en los documentos proporcionados para responder a esa pregunta. La Proposición 2.1 no se encuentra en los documentos proporcionados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "consulta_5 = \"what does the Notation say us?\"\n",
        "respuesta_5 = rag_chain.invoke(consulta_5)\n",
        "print(f\"Pregunta: {consulta_5}\")\n",
        "print(f\"Respuesta: {respuesta_5}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L3Ykwc_-pDh",
        "outputId": "0b99ff24-5ceb-4e69-e7e5-45ad39ea6f77"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregunta: what does the Notation say us?\n",
            "Respuesta: According to the Contexto, the Notation section provides a list of definitions for various mathematical symbols and expressions used throughout the paper. Specifically, it defines the following:\n",
            "\n",
            "* gcd: the greatest common divisor\n",
            "* lcm: the least common multiple\n",
            "* νℓ: the valuation with respect to ℓ, a prime number\n",
            "* k: the rational function field Fq(T)\n",
            "* RT: the polynomial ring Fq[T]\n",
            "* R+: the set of monic and irreducible polynomials in RT\n",
            "* S∞(K): the set of primes in K over P∞\n",
            "* ne∞(E/F): the ramification index of P∞ in the field extension E/F\n",
            "* nf∞(E/F): the inertia degree of P∞ in the field extension E/F\n",
            "* ΛN: the N-torsion of the Carlitz's module for N ∈ RT \\ {0}\n",
            "* Kge: the genus field of K\n",
            "* Kgex: the extended or narrow genus field of K\n",
            "* k(ΛN): the cyclotomic function field over k determined by N\n",
            "* k(ΛN)+: the maximum real subfield of k(ΛN)\n",
            "* Ln: the subfield of k(ΛT−n−1) fixed by F∗q\n",
            "* Km: the field KFqm\n",
            "* nK: the field KLn\n",
            "* nKm: the field KFqm Ln\n",
            "\n",
            "These definitions provide a foundation for understanding the mathematical concepts and results presented in the paper.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "consulta_6 = \"what is the origin of genus field?\"\n",
        "respuesta_6 = rag_chain.invoke(consulta_6)\n",
        "print(f\"Pregunta: {consulta_6}\")\n",
        "print(f\"Respuesta: {respuesta_6}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "707UrjvK_KU2",
        "outputId": "88053ef4-5ff2-4c5a-e1f5-6df99dad17ab"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregunta: what is the origin of genus field?\n",
            "Respuesta: De acuerdo con el contexto, el origen de los campos de género se remonta al trabajo de C. F. Gauss sobre formas cuadráticas binarias.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "consulta_7 = \"what does the M.Rosen's definition say?\"\n",
        "respuesta_7 = rag_chain.invoke(consulta_7)\n",
        "print(f\"Pregunta: {consulta_7}\")\n",
        "print(f\"Respuesta: {respuesta_7}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ii_kqo-_gZc",
        "outputId": "3beef6f0-7dfe-443f-bf0e-c708accf6e98"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregunta: what does the M.Rosen's definition say?\n",
            "Respuesta: Según el contexto, la definición de M. Rosen dice que el campo de clase de Hilbert (relativo a un conjunto S de lugares de un campo de función global K) es el máximo campo abeliano no ramificado de K tal que los lugares en S se descomponen completamente en él.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Una pequeña prueba con gradio"
      ],
      "metadata": {
        "id": "b2S_pUHVH519"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import gradio as gr"
      ],
      "metadata": {
        "collapsed": true,
        "id": "cC3EFgqLFNaB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d19c11d-629a-4920-cdcd-1c79b9b13774"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.13)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_chat(consulta):\n",
        "  return rag_chain.invoke(consulta)"
      ],
      "metadata": {
        "id": "FENmnkpRIMe5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interfaz = gr.Interface(fn=rag_chat, inputs=\"text\", outputs=\"text\")\n",
        "interfaz.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "mCtwJPyFIaPf",
        "outputId": "50993c93-2396-4124-ed05-bcc814fa0660"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0c2f98310a2fb45846.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0c2f98310a2fb45846.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}